{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "1.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras \n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random as rn\n",
    "import os\n",
    "print(keras.__version__)\n",
    "print(tf.__version__)\n",
    "\n",
    "# Utiliser un seed fixé pour le générateur de nombres aléatoires afin de résoudre le problème du caractère aléatoire et d'obtenir des résultats reproductibles avec Kéras. Les nombres ne font pas beaucoup de différence.\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prétraitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "158784it [14:39, 180.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "phrases=[]\n",
    "mots = []\n",
    "cibles=[] \n",
    "phr_position=0 \n",
    "\n",
    "labels= {'Correct':0, 'ArtOrDet':1, 'Nn':2, 'Prep':3, 'SVA':4, 'Vform':5, 'Vt':6, 'Wform':7}\n",
    "\n",
    " \n",
    "# Importer les phrases du fichier de données\n",
    "f=open('/Users/highsierra/Tech/Labortory/ML-Fundamentals/release3.2/data/conll14st-preprocessed.m2')\n",
    "for ligne in tqdm(f):\n",
    "    parties = ligne.split()\n",
    "    if(len(parties)>0):\n",
    "        if ligne[0]=='S':\n",
    "        # Traitement préliminaire des entrées   \n",
    "            \n",
    "            # Nettoyage\n",
    "            ligne = ligne[2:].strip()\n",
    "            \n",
    "            # Liste de phrases\n",
    "            phrases.append(ligne)\n",
    "\n",
    "            # Liste de mots, pour en déduire la liste de vocabulaire\n",
    "            mots = mots + ligne.split()\n",
    "\n",
    "            \n",
    "        # Traitement préliminaire des sorties   \n",
    "            \n",
    "            # Par défaut, considérer chaque mot comme non erroné, en créant un tableau avec l'étiquette \"Correct\" (i.e. sa valeur \"0\") pour chaque mot.\n",
    "            etiquettes=np.zeros(shape=(len(parties)-1), dtype='int32')\n",
    "            # Combiner verticalement les étiquettes associées à chaque phrase afin de les aligner avec les mots d'entrée\n",
    "            cibles.append(etiquettes)\n",
    "            # Conserver la position de la phrase en cours, afin de l'utiliser dans l'emplacement des étiquettes de ses mots\n",
    "            phr_position += 1\n",
    "            \n",
    "        elif parties[0]=='A':\n",
    "            if re.findall(\"ArtOrDet\", parties[2]) or re.findall(\"Nn\", parties[2]) or re.findall(\"Vt\", parties[2]) or re.findall(\"Prep\", parties[2]) or re.findall(\"Vform\", parties[2]) or re.findall(\"Wform\", parties[2]) or re.findall(\"SVA\", parties[2]):\n",
    "                # Conserver la position du mot erroné qui est extraite de l'annotation associée à la phrase en cours\n",
    "                digit = [int(j) for j in re.findall(\"[0-9]+\", parties[2][:2])]            \n",
    "    \n",
    "                for clé in labels:\n",
    "                    if  re.search(clé, parties[2]):\n",
    "                        err = labels.get(clé)\n",
    "                 \n",
    "                # En utilisant sa position extraite, placer l'étiquette du mot erroné dans sa phrase\n",
    "                cibles[phr_position - 1][digit[0]-1] = err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222\n"
     ]
    }
   ],
   "source": [
    "phr_lon = []\n",
    "for phr in phrases:\n",
    "    phr_lon.append(len(phr.split()))\n",
    "     \n",
    "MAX_SEQUENCE_LONGUEUR = max(phr_lon)\n",
    "print(MAX_SEQUENCE_LONGUEUR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33762\n"
     ]
    }
   ],
   "source": [
    "MAX_VOCAB_TAILLE = len(set(mots))\n",
    "print(MAX_VOCAB_TAILLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_TAILLE, filters='\\t\\n')\n",
    "tokenizer.fit_on_texts(phrases)\n",
    "sequences = tokenizer.texts_to_sequences(phrases)\n",
    "word2idx = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LONGUEUR, padding='post', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pad_sequences(cibles, maxlen=MAX_SEQUENCE_LONGUEUR, padding='post', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57151, 222)\n",
      "(57151, 222)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres de contrôle des expérimentations:\n",
    "UNITS=  25 #50 #100\n",
    "EMBEDDING_DIM = 200 #50 #100\n",
    "BATCH_TAILLE = 16 #32 #64   \n",
    "DROPOUT_VAL = 0.1 #0 #0.2\n",
    "\n",
    "# Constantes:\n",
    "EPOCHS = 3\n",
    "RECURRENT_DROPOUT_VAL = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:28, 14104.19it/s]\n"
     ]
    }
   ],
   "source": [
    "word2vec = {}\n",
    "with open(os.path.join('/Users/highsierra/Tech/Labortory/ML-Fundamentals/glove.6B/glove.6B.%sd.txt' % EMBEDDING_DIM)) as f:\n",
    "    for ligne in tqdm(f):\n",
    "        values = ligne.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29347/29347 [00:00<00:00, 100604.03it/s]\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((MAX_VOCAB_TAILLE,EMBEDDING_DIM))\n",
    "for word, i in tqdm(word2idx.items()):\n",
    "    embedding_vector = word2vec.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Répartir les phrases en ensembles de formation et de test selon les pourcentages: 80%, 20%\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout,Reshape, SimpleRNN, Bidirectional\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_(x_tr, y_tr, epos=3, my_batch_taille=BATCH_TAILLE):  \n",
    "    input = Input(shape=(MAX_SEQUENCE_LONGUEUR,)) \n",
    "    model = Embedding(input_dim=MAX_VOCAB_TAILLE, output_dim=EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LONGUEUR, trainable=False)(input)\n",
    "    model = LSTM(units=UNITS, return_sequences=True, recurrent_dropout=RECURRENT_DROPOUT_VAL)(model)\n",
    "    model = LSTM(units=UNITS, return_sequences=True, recurrent_dropout=RECURRENT_DROPOUT_VAL)(model)\n",
    "    #model = SimpleRNN(units=UNITS, return_sequences=True, recurrent_dropout=RECURRENT_DROPOUT_VAL)(model)\n",
    "    model = Dropout(DROPOUT_VAL)(model)\n",
    "    out = TimeDistributed(Dense(8, activation='softmax'))(model)\n",
    "    model = Model(input, out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/miniconda3/envs/tensorflow1/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = Model_(X_train,  y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour la formation et le test du modèle dans Keras, nous devons convertir l'ensemble des étiquettes ou des sorties (y) en catégoriels.\n",
    "\n",
    "ycat_train = to_categorical(y_train, num_classes=8)\n",
    "ycat_test = to_categorical(y_test, num_classes=8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/miniconda3/envs/tensorflow1/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/tensorflow1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/3\n",
      "45720/45720 [==============================] - 2847s 62ms/step - loss: 0.0307 - accuracy: 0.9980\n",
      "Epoch 2/3\n",
      "45720/45720 [==============================] - 2555s 56ms/step - loss: 0.0114 - accuracy: 0.9983\n",
      "Epoch 3/3\n",
      "45720/45720 [==============================] - 3135s 69ms/step - loss: 0.0105 - accuracy: 0.9983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a680ede90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, ycat_train, epochs=EPOCHS, batch_size=BATCH_TAILLE, verbose=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation\n",
    "Calculez les mesures suivantes :\n",
    "1. Accuracy\n",
    "2. Précision\n",
    "3. Rappel\n",
    "4. F1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11431/11431 [==============================] - 79s 7ms/step\n",
      "Accuracy: 99.83%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, ycat_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11431/11431 [==============================] - 71s 6ms/step\n",
      "(11431, 222, 8)\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test, verbose=1) \n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(pred,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tensorflow1/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8642896614574509\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "pres_score = []\n",
    "\n",
    "for tru,pred in zip (y_test, y_pred):\n",
    "    pres_score.append(precision_score(tru,pred,average='macro'))\n",
    "\n",
    "precision = np.mean(pres_score)\n",
    "print(precision) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8649695273087803\n"
     ]
    }
   ],
   "source": [
    "rec_score = []\n",
    "\n",
    "for tru,pred in zip (y_test, y_pred):\n",
    "    rec_score.append(recall_score(tru,pred,average='macro'))\n",
    "\n",
    "rappel = np.mean(rec_score)\n",
    "print(rappel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8646282468000843\n"
     ]
    }
   ],
   "source": [
    "# Manuellement, le F1-score est calculé selon la formule :  f1 = (2 * precision * rappel) / (precision + rappel)\n",
    "f_score = []\n",
    "\n",
    "for tru,pred in zip (y_test, y_pred):\n",
    "    f_score.append(f1_score(tru,pred,average='macro'))\n",
    "f1 = np.mean(f_score)\n",
    "print(f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow1)",
   "language": "python",
   "name": "tensorflow1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
